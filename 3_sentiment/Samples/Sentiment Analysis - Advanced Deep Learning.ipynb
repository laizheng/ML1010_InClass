{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary depencencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import text_normalizer as tn\n",
    "import model_evaluation_utils as meu\n",
    "import pydot\n",
    "\n",
    "np.set_printoptions(precision=2, linewidth=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  not bother think would see movie great supspen...  negative\n",
      "1  careful one get mitt change way look kung fu f...  positive\n",
      "2  chili palmer tired movie know want success mus...  negative\n",
      "3  follow little know 1998 british film make budg...  positive\n",
      "4  dark angel cross huxley brave new world percys...  positive\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'movie_reviews_cleaned.csv')\n",
    "# take a peek at the data\n",
    "print(dataset.head())\n",
    "reviews = np.array(dataset['review'])\n",
    "sentiments = np.array(dataset['sentiment'])\n",
    "\n",
    "# build train and test datasets\n",
    "norm_train_reviews = reviews[:35000]\n",
    "norm_train_sentiments = sentiments[:35000]\n",
    "norm_test_reviews = reviews[35000:]\n",
    "norm_test_sentiments = sentiments[35000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize train & test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = [tn.tokenizer.tokenize(text) for text in norm_train_reviews]\n",
    "tokenized_test = [tn.tokenizer.tokenize(text) for text in norm_test_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Vocabulary Mapping (word to index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 80004\n",
      "Sample slice of vocabulary map: {'boring': 11, 'terribly': 12, 'predictable': 13, 'interesting': 14, 'start': 15, 'middle': 16, 'film': 17, 'little': 18, 'social': 19, 'drama': 20}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# build word to index vocabulary\n",
    "token_counter = Counter([token for review in tokenized_train for token in review])\n",
    "vocab_map = {item[0]: index+1 for index, item in enumerate(dict(token_counter).items())}\n",
    "max_index = np.max(list(vocab_map.values()))\n",
    "vocab_map['PAD_INDEX'] = 0\n",
    "vocab_map['NOT_FOUND_INDEX'] = max_index+1\n",
    "vocab_size = len(vocab_map)\n",
    "# view vocabulary size and part of the vocabulary map\n",
    "print('Vocabulary Size:', vocab_size)\n",
    "print('Sample slice of vocabulary map:', dict(list(vocab_map.items())[10:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode and Pad datasets & Encode prediction class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of train review vectors: 1115\n",
      "Train review vectors shape: (35000, 1115)  Test review vectors shape: (15000, 1115)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# get max length of train corpus and initialize label encoder\n",
    "le = LabelEncoder()\n",
    "num_classes=2 # positive -> 1, negative -> 0\n",
    "max_len = np.max([len(review) for review in tokenized_train])\n",
    "\n",
    "## Train reviews data corpus\n",
    "# Convert tokenized text reviews to numeric vectors\n",
    "train_X = [[vocab_map[token] for token in tokenized_review] for tokenized_review in tokenized_train]\n",
    "train_X = sequence.pad_sequences(train_X, maxlen=max_len) # pad \n",
    "## Train prediction class labels\n",
    "# Convert text sentiment labels (negative\\positive) to binary encodings (0/1)\n",
    "train_y = le.fit_transform(norm_train_sentiments)\n",
    "\n",
    "## Test reviews data corpus\n",
    "# Convert tokenized text reviews to numeric vectors\n",
    "test_X = [[vocab_map[token] if vocab_map.get(token) else vocab_map['NOT_FOUND_INDEX'] \n",
    "           for token in tokenized_review] \n",
    "              for tokenized_review in tokenized_test]\n",
    "test_X = sequence.pad_sequences(test_X, maxlen=max_len)\n",
    "## Test prediction class labels\n",
    "# Convert text sentiment labels (negative\\positive) to binary encodings (0/1)\n",
    "test_y = le.transform(norm_test_sentiments)\n",
    "\n",
    "# view vector shapes\n",
    "print('Max length of train review vectors:', max_len)\n",
    "print('Train review vectors shape:', train_X.shape, ' Test review vectors shape:', test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the LSTM Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, SpatialDropout1D\n",
    "from keras.layers import LSTM\n",
    "\n",
    "EMBEDDING_DIM = 128 # dimension for dense embeddings for each token\n",
    "LSTM_DIM = 64 # total LSTM units\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=max_len))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(LSTM_DIM, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1115, 128)         10240512  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 1115, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 10,289,985\n",
      "Trainable params: 10,289,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"78pt\" viewBox=\"0.00 0.00 1044.00 78.00\" width=\"1044pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 74)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-74 1040,-74 1040,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 112867511936 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>112867511936</title>\n",
       "<polygon fill=\"none\" points=\"137,-.5 137,-69.5 347,-69.5 347,-.5 137,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242\" y=\"-54.3\">Embedding</text>\n",
       "<polyline fill=\"none\" points=\"137,-46.5 347,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"187.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"238,-23.5 238,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-31.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"137,-23.5 347,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"182.5\" y=\"-8.3\">(None, 1115)</text>\n",
       "<polyline fill=\"none\" points=\"228,-.5 228,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-8.3\">(None, 1115, 128)</text>\n",
       "</g>\n",
       "<!-- 112867490448 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>112867490448</title>\n",
       "<polygon fill=\"none\" points=\"383,-.5 383,-69.5 621,-69.5 621,-.5 383,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"502\" y=\"-54.3\">SpatialDropout1D</text>\n",
       "<polyline fill=\"none\" points=\"383,-46.5 621,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"440.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"498,-23.5 498,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"559.5\" y=\"-31.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"383,-23.5 621,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"442.5\" y=\"-8.3\">(None, 1115, 128)</text>\n",
       "<polyline fill=\"none\" points=\"502,-.5 502,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"561.5\" y=\"-8.3\">(None, 1115, 128)</text>\n",
       "</g>\n",
       "<!-- 112867511936&#45;&gt;112867490448 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>112867511936-&gt;112867490448</title>\n",
       "<path d=\"M347.0025,-35C355.5116,-35 364.1691,-35 372.8218,-35\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"372.9679,-38.5001 382.9679,-35 372.9678,-31.5001 372.9679,-38.5001\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 113072913880 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>113072913880</title>\n",
       "<polygon fill=\"none\" points=\"657,-.5 657,-69.5 853,-69.5 853,-.5 657,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"755\" y=\"-54.3\">LSTM</text>\n",
       "<polyline fill=\"none\" points=\"657,-46.5 853,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"704\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"751,-23.5 751,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"802\" y=\"-31.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"657,-23.5 853,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"716.5\" y=\"-8.3\">(None, 1115, 128)</text>\n",
       "<polyline fill=\"none\" points=\"776,-.5 776,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"814.5\" y=\"-8.3\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 112867490448&#45;&gt;113072913880 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>112867490448-&gt;113072913880</title>\n",
       "<path d=\"M621.0917,-35C629.5656,-35 638.0839,-35 646.494,-35\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"646.6885,-38.5001 656.6885,-35 646.6884,-31.5001 646.6885,-38.5001\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 113072913264 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>113072913264</title>\n",
       "<polygon fill=\"none\" points=\"889,-.5 889,-69.5 1036,-69.5 1036,-.5 889,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"962.5\" y=\"-54.3\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"889,-46.5 1036,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"924\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"959,-23.5 959,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"997.5\" y=\"-31.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"889,-23.5 1036,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"927.5\" y=\"-8.3\">(None, 64)</text>\n",
       "<polyline fill=\"none\" points=\"966,-.5 966,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1001\" y=\"-8.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 113072913880&#45;&gt;113072913264 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>113072913880-&gt;113072913264</title>\n",
       "<path d=\"M853.2811,-35C861.7708,-35 870.3095,-35 878.6689,-35\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"878.7613,-38.5001 888.7613,-35 878.7613,-31.5001 878.7613,-38.5001\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 113072912984 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>113072912984</title>\n",
       "<polygon fill=\"none\" points=\"0,-17 0,-53 101,-53 101,-17 0,-17\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"50.5\" y=\"-31.3\">113072912984</text>\n",
       "</g>\n",
       "<!-- 113072912984&#45;&gt;112867511936 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>113072912984-&gt;112867511936</title>\n",
       "<path d=\"M101.0649,-35C109.1966,-35 117.8924,-35 126.8237,-35\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"126.99,-38.5001 136.9899,-35 126.9899,-31.5001 126.99,-38.5001\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True, show_layer_names=False, \n",
    "                 rankdir='LR').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31500 samples, validate on 3500 samples\n",
      "Epoch 1/5\n",
      "31500/31500 [==============================] - 476s 15ms/step - loss: 0.4036 - acc: 0.8192 - val_loss: 0.2964 - val_acc: 0.8846\n",
      "Epoch 2/5\n",
      "31500/31500 [==============================] - 479s 15ms/step - loss: 0.2226 - acc: 0.9157 - val_loss: 0.2889 - val_acc: 0.8926\n",
      "Epoch 3/5\n",
      "31500/31500 [==============================] - 474s 15ms/step - loss: 0.1477 - acc: 0.9487 - val_loss: 0.3240 - val_acc: 0.8794\n",
      "Epoch 4/5\n",
      "31500/31500 [==============================] - 462s 15ms/step - loss: 0.0991 - acc: 0.9660 - val_loss: 0.3402 - val_acc: 0.8857\n",
      "Epoch 5/5\n",
      "31500/31500 [==============================] - 471s 15ms/step - loss: 0.0896 - acc: 0.9697 - val_loss: 0.4066 - val_acc: 0.8857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a61c0cf60>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "model.fit(train_X, train_y, epochs=5, batch_size=batch_size, \n",
    "          shuffle=True, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/james/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict_classes(test_X)\n",
    "predictions = le.inverse_transform(pred_test.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.8752\n",
      "Precision: 0.8755\n",
      "Recall: 0.8752\n",
      "F1 Score: 0.8752\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.87      0.89      0.88      7587\n",
      "   negative       0.88      0.86      0.87      7413\n",
      "\n",
      "avg / total       0.88      0.88      0.88     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6759      828\n",
      "        negative       1044     6369\n"
     ]
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(true_labels=norm_test_sentiments, predicted_labels=predictions, \n",
    "                                      classes=['positive', 'negative'])  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
